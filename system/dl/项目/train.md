场景a. 最开始已知信息极少,但需要明确基本的需求:
场景a动作: 列出基本需求后,列举已知的信息,计划使用成熟的BM25+LSTM+Bert解决.
结果a: 但执行过程中,估计此模型难以优化,且参数无法复用.

场景b. 即结果a.
场景b动作:

1. 使用PLM(预训练语言模型), 及delta-finetune(增量微调)技术
2. 学习Prompt,微调方法原理,打算手工实现.
3. 选择先在Python上进行实验.但意外发现一些大模型训练框架,转向收集框架信息.
结果b: 学习大模型相关课程,并进行实验.与未优化比,估计情况为:
训练: 10B Model 从16张到4张,并提速6倍
压缩: 保持原模型90%+效果,模型推理加速10倍
推理: 可以在1060执行1.6Token/s.不考虑等待时间,10B模型只需500MB显存.
产生新计划: 优化rust-bert,将以上功能实现以rust.

场景c: 需实现下游任务IR,QA,TG.
场景c动作:

1. IR上,开始方案是计算词向量相似度.后修改为召回重排.
2. TG暂时直接使用T5.
结果c:基本实现了需求,并大致生成计划事项,如:
1. 借鉴RocketQA流水线,或对比学习的工程技巧.
2. 专业领域微调结果分析等.
3. (召回理论@10 rerank-0.67 retrieval-0.64,但也会只有0.40+)
4. 使用autoCoT.

[具体过程](./train_detail.md)